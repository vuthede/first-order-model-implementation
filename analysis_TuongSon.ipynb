{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuongnv88/miniconda3/envs/devt/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOOOOOOOOOOO dense_motion_params :{'block_expansion': 64, 'max_features': 1024, 'num_blocks': 5, 'scale_factor': 0.25, 'using_first_order_motion': False, 'using_thin_plate_spline_motion': True}\n",
      "Use predefined train-test split.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset\n",
    "from dataset.frames_dataset_with_lmks import FramesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Models\n",
    "\n",
    "from modulesiris.generator import OcclusionAwareGenerator\n",
    "import imageio\n",
    "\n",
    "# Loss\n",
    "device = 'cuda'\n",
    "\n",
    "def load_model(ckpt):\n",
    "    checkpoint = torch.load(ckpt, map_location=device)\n",
    "     # Model here\n",
    "    dense_motion_params = {\"block_expansion\":64, \"max_features\": 1024, \"num_blocks\":5, \"scale_factor\":0.25, \"using_first_order_motion\":False,\"using_thin_plate_spline_motion\":True}\n",
    "    G = OcclusionAwareGenerator(num_channels=3, num_kp=8, block_expansion=64, max_features=512, num_down_blocks=2,\n",
    "                 num_bottleneck_blocks=6, estimate_occlusion_map=True, dense_motion_params=dense_motion_params, estimate_jacobian=True)\n",
    "    \n",
    "    G.load_state_dict(checkpoint[\"G_state_dict\"], strict=True)\n",
    "    G = G.to(device)\n",
    "    return G\n",
    "\n",
    "def draw_landmarks(img, lmks, color=(255,0,0)):\n",
    "    img = np.ascontiguousarray(img)\n",
    "    for a in lmks:\n",
    "        cv2.circle(img,(int(round(a[0])), int(round(a[1]))), 1, color, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def vis(x, x_prime_hat, kp_src, kp_driving):\n",
    "        \"\"\"\n",
    "        x: Bx3x1xHxW\n",
    "        x_prime: Bx3x1xHxW\n",
    "        x_prime_hat: Bx3x1xHxW\n",
    "        kp_src: Bx1x10x2\n",
    "        kp_driving: Bx1x10x2\n",
    "        \"\"\"\n",
    "        _,_,h,w = x.shape\n",
    "        x = x.detach().cpu().numpy()\n",
    "        x_prime_hat = x_prime_hat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        kp_src = kp_src.detach().cpu().numpy()\n",
    "        kp_driving = kp_driving.detach().cpu().numpy()\n",
    "\n",
    "        for i, (x1, x3, ks, kd) in enumerate(zip(x, x_prime_hat, kp_src, kp_driving)):\n",
    "            x1 = (np.transpose(x1, (1,2,0))*255.0).astype(np.uint8)\n",
    "            x3 = (np.transpose(x3, (1,2,0))*255.0).astype(np.uint8)\n",
    "            ks = (ks+1) * np.array([w,h]) / 2.0\n",
    "            kd = (kd+1) * np.array([w,h]) / 2.0\n",
    "            x1 = draw_landmarks(x1, ks)\n",
    "            x3 = draw_landmarks(x3, ks)\n",
    "            x3 = draw_landmarks(x3, kd, color=(0,255,255))\n",
    "\n",
    "            img = np.hstack((x1, x3))\n",
    "            return img\n",
    "\n",
    "\n",
    "\n",
    "def synthize_kp_driving(kp_src, delta_x=None, delta_y=None):\n",
    "    kp_driving = {}\n",
    "    kp_driving[\"value\"] =  kp_src[\"value\"].clone()\n",
    "\n",
    "    if delta_x is  None:\n",
    "        delta_x = np.random.uniform(-0.15, 0.15)\n",
    "    if delta_y is  None:\n",
    "        delta_y = np.random.uniform(-0.15, 0.15)\n",
    "\n",
    "    kp_driving[\"value\"][:,-2:,0] = kp_driving[\"value\"][:,-2:,0] + delta_x\n",
    "    kp_driving[\"value\"][:,-2:,1] = kp_driving[\"value\"][:,-2:,1] + delta_y\n",
    "    return kp_driving\n",
    "\n",
    "\n",
    "from skimage import io, img_as_float32\n",
    "\n",
    "# Load model\n",
    "# ckpt = \"checkpoints/motion_iris/11.pth.tar\"\n",
    "# ckpt = \"checkpoints/motion_iris_fix_motion_equation/15.pth.tar\"\n",
    "# ckpt = \"checkpoints/motion_iris_fix_motion_test/8.pth.tar\"\n",
    "# ckpt = \"checkpoints/motion_iris_thin_plate_spline_motion/20.pth.tar\"\n",
    "ckpt = \"checkpoints/motion_iris_thin_plate_spline_motion_more_control_points/3.pth.tar\"\n",
    "\n",
    "\n",
    "\n",
    "G = load_model(ckpt = ckpt)\n",
    "G.eval()\n",
    "\n",
    "# Dataset\n",
    "root_dir = \"./data/eth_motion_data\"\n",
    "augmentation_params = {\"flip_param\" : {\"horizontal_flip\": False, \"time_flip\":False}, \"jitter_param\" :{\"brightness\":0.1, \"contrast\":0.1, \"saturation\":0.1, \"hue\":0.1}}\n",
    "dataset = FramesDataset(root_dir, frame_shape=(256, 256, 3), id_sampling=False, is_train=True,\n",
    "             random_seed=0, pairs_list=None, augmentation_params=augmentation_params)\n",
    "\n",
    "\n",
    "# batchdata = dataset[index]\n",
    "# _, x = batchdata[\"driving\"], batchdata[\"source\"]\n",
    "# _, kp_src = batchdata[\"lmks_driving\"], batchdata[\"lmks_source\"]\n",
    "\n",
    "# Fake image\n",
    "def synthesize_image(src_path, delta_x, delta_y):\n",
    "    src = cv2.imread(src_path)\n",
    "    src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    src = cv2.resize(src, (256, 256)) #BxCxDxH,W\n",
    "    src = src/255.0\n",
    "    x  = np.transpose(src, (2,0,1)) # 3x256x256\n",
    "    kp_src = {\"value\": torch.FloatTensor([[-0.2136181,-0.31389177],[0.373667,-0.22871798]])}\n",
    "\n",
    "\n",
    "    x = torch.FloatTensor(x)\n",
    "    kp_src[\"value\"] = torch.FloatTensor(kp_src[\"value\"])\n",
    "    x = x.to(device) \n",
    "    kp_src[\"value\"] = kp_src[\"value\"].to(device)\n",
    "    kp_src[\"value\"].unsqueeze_(0) \n",
    "    x.unsqueeze_(0) \n",
    "    kp_driving = synthize_kp_driving(kp_src, delta_x, delta_y)\n",
    "    kp_driving[\"value\"] = kp_driving[\"value\"].to(device)\n",
    "    prediction = G(source_image=x, kp_driving=kp_driving, kp_source=kp_src)\n",
    "    img_out = vis(x, prediction[\"prediction\"], kp_src[\"value\"], kp_driving[\"value\"])\n",
    "\n",
    "    return img_out, prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c2233793b5482f80164bc21547faac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='delta_x', max=0.15, min=-0.15, step=0.005), FloatSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual, Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "@interact(delta_x=(-0.15, 0.15, 0.005), delta_y=(-0.15, 0.15, 0.005))\n",
    "def synthesize(delta_x, delta_y):\n",
    "    img, prediction = synthesize_image(src_path=\"trinh.png\", delta_x=delta_x, delta_y=delta_y)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img_bytes = cv2.imencode('.png', img)[1].tobytes()\n",
    "    widget = Image(value=img_bytes, format='png')\n",
    "    return (widget)\n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('devt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b407b6cc7cd8737f4a857c7236b85d4b17aabd0cc56036e7d8ab66b3501374f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
